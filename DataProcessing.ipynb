{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f51f19c",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "The code organizes the dataset of images into training and test sets for three categories: human, dalle, and stable. Random samples are selected from each category for training and the remaining samples are used for testing. The images are preprocessed, resized, and converted into numpy arrays. Training and test batches are created and saved as pickle files for later use."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T13:41:23.173251Z",
     "start_time": "2024-11-01T13:41:22.830831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle as pkl\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import webp\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_random_samples(file_list, sample_size):\n",
    "    \"\"\"Randomly selects samples from the given file list.\"\"\"\n",
    "    return random.sample(file_list, sample_size)\n",
    "\n",
    "def get_remaining_samples(file_list, selected_samples):\n",
    "    \"\"\"Returns the samples not selected from the file list.\"\"\"\n",
    "    return [sample for sample in file_list if sample not in selected_samples]\n",
    "\n",
    "def preprocess_image(image_path, target_size):\n",
    "    \"\"\"Loads and preprocesses the image from the given path.\"\"\"\n",
    "    img = Image.open(image_path).resize(target_size)\n",
    "    return np.array(img.convert(\"RGB\")) / 255.\n",
    "\n",
    "def preprocess_webp_image(image_path, target_size, crop_size):\n",
    "    \"\"\"Loads and preprocesses the WebP image from the given path.\"\"\"\n",
    "    img = webp.load_image(image_path, 'RGB').resize(target_size).crop(crop_size)\n",
    "    return np.array(img) / 255.\n",
    "\n",
    "def save_pickle_file(data, file_path):\n",
    "    \"\"\"Saves the data as a pickle file at the specified path.\"\"\"\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pkl.dump(data, f)\n",
    "\n",
    "def create_batches(file_paths, folder, batch_size):\n",
    "    \"\"\"Creates batches of images and labels from the given file paths.\"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    for path in file_paths:\n",
    "        img = preprocess_image(os.path.join(folder, path), (255, 245))\n",
    "        data.append(img)\n",
    "        labels.append([1, 0, 0])  # Change label based on category\n",
    "\n",
    "    return np.stack(data), np.array(labels)\n",
    "\n",
    "def create_webp_batches(file_paths, folder, batch_size):\n",
    "    \"\"\"Creates batches of WebP images and labels from the given file paths.\"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    for path in file_paths:\n",
    "        img = preprocess_webp_image(os.path.join(folder, path), (256, 256), (0, 0, 255, 245))\n",
    "        data.append(img)\n",
    "        labels.append([0, 1, 0])  # Change label based on category\n",
    "\n",
    "    return np.stack(data), np.array(labels)\n",
    "\n",
    "def organize_data(human_path, ai_path, folder):\n",
    "    # Image locations\n",
    "    print(\"Initializing paths...\")\n",
    "    human_path = human_path\n",
    "    ai_path = ai_path\n",
    "\n",
    "    # Create a new folder to save information\n",
    "    if not os.path.exists(folder + 'file_names/'):\n",
    "        os.makedirs(folder + 'file_names/')\n",
    "        print(f\"Created folder: {folder}file_names/\")\n",
    "    if not os.path.exists(folder + 'train_batches/'):\n",
    "        os.makedirs(folder + 'train_batches/')\n",
    "        print(f\"Created folder: {folder}train_batches/\")\n",
    "    if not os.path.exists(folder + 'test_batches/'):\n",
    "        os.makedirs(folder + 'test_batches/')\n",
    "        print(f\"Created folder: {folder}test_batches/\")\n",
    "\n",
    "    # Randomly select test and training samples for each category\n",
    "    human_files = os.listdir(human_path)\n",
    "    print(f\"Found {len(human_files)} human files.\")\n",
    "    human_train = get_random_samples(human_files, 200)\n",
    "    print(f\"Selected {len(human_train)} human train samples.\")\n",
    "    human_test = get_remaining_samples(human_files, human_train)\n",
    "    print(f\"Remaining human test samples: {len(human_test)}\")\n",
    "\n",
    "    ai_files = os.listdir(ai_path)\n",
    "    print(f\"Found {len(ai_files)} AI files.\")\n",
    "    ai_train = get_random_samples(ai_files, 150)\n",
    "    print(f\"Selected {len(ai_train)} AI train samples.\")\n",
    "    ai_test = get_remaining_samples(ai_files, ai_train)\n",
    "    print(f\"Remaining AI test samples: {len(ai_test)}\")\n",
    "\n",
    "    # Save the train and test sample names as pickle files\n",
    "    save_pickle_file([human_train, ai_train], folder + 'file_names/train.pickle')\n",
    "    print(\"Saved train sample names to train.pickle.\")\n",
    "    save_pickle_file([human_test, ai_test], folder + 'file_names/test.pickle')\n",
    "    print(\"Saved test sample names to test.pickle.\")\n",
    "\n",
    "    # Create training batches\n",
    "    num_batches = 10\n",
    "    batch_size = 15\n",
    "    print(f\"Creating {num_batches} batches with batch size of {batch_size}...\")\n",
    "    for batch in tqdm(range(num_batches)):\n",
    "        human_train_batch = human_train[batch * batch_size:(batch + 1) * batch_size]\n",
    "        ai_train_batch = ai_train[batch * batch_size:(batch + 1) * batch_size]\n",
    "\n",
    "        # Process and save batches\n",
    "        print(f\"Processing batch {batch + 1}/{num_batches}...\")\n",
    "        human_data, human_labels = create_batches(human_train_batch, human_path, batch_size)\n",
    "        print(f\"Processed human batch {batch + 1}: {human_data.shape} images.\")\n",
    "        \n",
    "        ai_data, ai_labels = create_batches(ai_train_batch, ai_path, batch_size)\n",
    "        print(f\"Processed AI batch {batch + 1}: {ai_data.shape} images.\")\n",
    "\n",
    "        # Stack and save batch data\n",
    "        data_batch = np.vstack((human_data, ai_data))\n",
    "        label_batch = np.vstack((human_labels, ai_labels))\n",
    "        batch_data = {'data': data_batch, 'labels': label_batch}\n",
    "\n",
    "        save_pickle_file(batch_data, f\"{folder}train_batches/batch_{batch}.pickle\")\n",
    "        print(f\"Saved batch {batch} to {folder}train_batches/batch_{batch}.pickle\")\n",
    "\n",
    "\n",
    "    # Repeat the process for test data\n",
    "    human_test_data, human_test_labels = create_batches(human_test, human_path, batch_size)\n",
    "    ai_test_data, ai_test_labels = create_batches(ai_test, ai_path, batch_size)\n",
    "\n",
    "    # Stack test data and save\n",
    "    test_data = np.vstack((human_test_data, ai_test_data))\n",
    "    test_labels = np.vstack((human_test_labels, ai_test_labels))\n",
    "    test_batch = {'data': test_data, 'labels': test_labels}\n",
    "    save_pickle_file(test_batch, f\"{folder}test_batches/test_batch.pickle\")\n",
    "\n",
    "\n",
    "organize_data(\"/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Dataset/human\",\n",
    "              \"/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Dataset/ai_generated\",\n",
    "              \"/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/\")"
   ],
   "id": "fbff5cd9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing paths...\n",
      "Found 213 human files.\n",
      "Selected 200 human train samples.\n",
      "Remaining human test samples: 13\n",
      "Found 187 AI files.\n",
      "Selected 150 AI train samples.\n",
      "Remaining AI test samples: 37\n",
      "Saved train sample names to train.pickle.\n",
      "Saved test sample names to test.pickle.\n",
      "Creating 10 batches with batch size of 15...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:00, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/10...\n",
      "Processed human batch 1: (15, 245, 255, 3) images.\n",
      "Processed AI batch 1: (15, 245, 255, 3) images.\n",
      "Saved batch 0 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_0.pickle\n",
      "Processing batch 2/10...\n",
      "Processed human batch 2: (15, 245, 255, 3) images.\n",
      "Processed AI batch 2: (15, 245, 255, 3) images.\n",
      "Saved batch 1 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_1.pickle\n",
      "Processing batch 3/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:00<00:00, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed human batch 3: (15, 245, 255, 3) images.\n",
      "Processed AI batch 3: (15, 245, 255, 3) images.\n",
      "Saved batch 2 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_2.pickle\n",
      "Processing batch 4/10...\n",
      "Processed human batch 4: (15, 245, 255, 3) images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file '/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Dataset/ai_generated/.DS_Store'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnidentifiedImageError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 128\u001B[0m\n\u001B[1;32m    124\u001B[0m     test_batch \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m: test_data, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m: test_labels}\n\u001B[1;32m    125\u001B[0m     save_pickle_file(test_batch, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfolder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mtest_batches/test_batch.pickle\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 128\u001B[0m \u001B[43morganize_data\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Dataset/human\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m              \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Dataset/ai_generated\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m              \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[27], line 105\u001B[0m, in \u001B[0;36morganize_data\u001B[0;34m(human_path, ai_path, folder)\u001B[0m\n\u001B[1;32m    102\u001B[0m human_data, human_labels \u001B[38;5;241m=\u001B[39m create_batches(human_train_batch, human_path, batch_size)\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessed human batch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhuman_data\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m images.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 105\u001B[0m ai_data, ai_labels \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_batches\u001B[49m\u001B[43m(\u001B[49m\u001B[43mai_train_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mai_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessed AI batch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mai_data\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m images.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    108\u001B[0m \u001B[38;5;66;03m# Stack and save batch data\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[27], line 37\u001B[0m, in \u001B[0;36mcreate_batches\u001B[0;34m(file_paths, folder, batch_size)\u001B[0m\n\u001B[1;32m     35\u001B[0m labels \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m path \u001B[38;5;129;01min\u001B[39;00m file_paths:\n\u001B[0;32m---> 37\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocess_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfolder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m255\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m245\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m     data\u001B[38;5;241m.\u001B[39mappend(img)\n\u001B[1;32m     39\u001B[0m     labels\u001B[38;5;241m.\u001B[39mappend([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m])  \u001B[38;5;66;03m# Change label based on category\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[27], line 19\u001B[0m, in \u001B[0;36mpreprocess_image\u001B[0;34m(image_path, target_size)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpreprocess_image\u001B[39m(image_path, target_size):\n\u001B[1;32m     18\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Loads and preprocesses the image from the given path.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_path\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mresize(target_size)\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(img\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m\"\u001B[39m)) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255.\u001B[39m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/PIL/Image.py:3536\u001B[0m, in \u001B[0;36mopen\u001B[0;34m(fp, mode, formats)\u001B[0m\n\u001B[1;32m   3534\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message)\n\u001B[1;32m   3535\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot identify image file \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (filename \u001B[38;5;28;01mif\u001B[39;00m filename \u001B[38;5;28;01melse\u001B[39;00m fp)\n\u001B[0;32m-> 3536\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m UnidentifiedImageError(msg)\n",
      "\u001B[0;31mUnidentifiedImageError\u001B[0m: cannot identify image file '/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Dataset/ai_generated/.DS_Store'"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "fe97613e7378c577"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "191611fd384d9acb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b3dc90ccfe2159f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
