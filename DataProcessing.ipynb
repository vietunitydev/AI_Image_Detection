{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f51f19c",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "The code organizes the dataset of images into training and test sets for three categories: human, dalle, and stable. Random samples are selected from each category for training and the remaining samples are used for testing. The images are preprocessed, resized, and converted into numpy arrays. Training and test batches are created and saved as pickle files for later use."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T13:10:14.543833Z",
     "start_time": "2024-11-19T13:04:05.873672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle as pkl\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_random_samples(file_list, sample_size):\n",
    "    return random.sample(file_list, sample_size)\n",
    "\n",
    "def get_remaining_samples(file_list, selected_samples):\n",
    "    return [sample for sample in file_list if sample not in selected_samples]\n",
    "\n",
    "def preprocess_image(image_path, target_size):\n",
    "    img = Image.open(image_path).resize(target_size)\n",
    "    return np.array(img.convert(\"RGB\")) / 255.\n",
    "\n",
    "def save_pickle_file(data, file_path):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pkl.dump(data, f)\n",
    "\n",
    "def create_batches_with_labels(file_paths, folder, label):\n",
    "    data = []\n",
    "    labels = []\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.webp']\n",
    "    \n",
    "    for path in file_paths:\n",
    "        if os.path.splitext(path)[1].lower() in valid_extensions:\n",
    "            img = preprocess_image(os.path.join(folder, path), (256, 256))\n",
    "            data.append(img)\n",
    "            labels.append(label)  \n",
    "        else:\n",
    "            print(f\"Skipped non-image file: {path}\")\n",
    "\n",
    "    return np.stack(data), np.array(labels)\n",
    "\n",
    "def organize_data(human_path, ai_path, folder):\n",
    "    human_path = human_path\n",
    "    ai_path = ai_path\n",
    "\n",
    "    if not os.path.exists(folder + 'file_names/'):\n",
    "        os.makedirs(folder + 'file_names/')\n",
    "    if not os.path.exists(folder + 'train_batches/'):\n",
    "        os.makedirs(folder + 'train_batches/')\n",
    "    if not os.path.exists(folder + 'test_batches/'):\n",
    "        os.makedirs(folder + 'test_batches/')\n",
    "\n",
    "    human_files = os.listdir(human_path)\n",
    "    human_train = get_random_samples(human_files, 7000)\n",
    "    human_test = get_remaining_samples(human_files, human_train)\n",
    "\n",
    "    ai_files = os.listdir(ai_path)\n",
    "    ai_train = get_random_samples(ai_files, 7000)\n",
    "    ai_test = get_remaining_samples(ai_files, ai_train)\n",
    "\n",
    "    save_pickle_file([human_train, ai_train], folder + 'file_names/train.pickle')\n",
    "    save_pickle_file([human_test, ai_test], folder + 'file_names/test.pickle')\n",
    "\n",
    "    num_batches = 20\n",
    "    batch_size = 350\n",
    "    \n",
    "    human_label = [0, 1]\n",
    "    ai_label = [1, 0]\n",
    "    \n",
    "    for batch in tqdm(range(num_batches)):\n",
    "        human_train_batch = human_train[batch * batch_size:(batch + 1) * batch_size]\n",
    "        ai_train_batch = ai_train[batch * batch_size:(batch + 1) * batch_size]\n",
    "\n",
    "        human_data, human_labels = create_batches_with_labels(human_train_batch, human_path, human_label)\n",
    "        \n",
    "        ai_data, ai_labels = create_batches_with_labels(ai_train_batch, ai_path, ai_label)\n",
    "\n",
    "        data_batch = {'data': np.vstack((human_data, ai_data)), \n",
    "                      'labels': np.vstack((human_labels, ai_labels))}\n",
    "\n",
    "        if data_batch['data'].size > 0 and data_batch['labels'].size > 0:\n",
    "            save_pickle_file(data_batch, f\"{folder}train_batches/batch_{batch}.pickle\")\n",
    "        else:\n",
    "            print(f\"Warning: Batch {batch} is empty and will not be saved.\")\n",
    "\n",
    "    # Repeat the process for test data\n",
    "    human_test_data, human_test_labels = create_batches_with_labels(human_test, human_path, human_label)\n",
    "    ai_test_data, ai_test_labels = create_batches_with_labels(ai_test, ai_path, ai_label)\n",
    "\n",
    "    # Stack test data and save\n",
    "    test_data = np.vstack((human_test_data, ai_test_data))\n",
    "    test_labels = np.vstack((human_test_labels, ai_test_labels))\n",
    "    test_batch = {'data': test_data, 'labels': test_labels}\n",
    "    save_pickle_file(test_batch, f\"{folder}test_batches/test_batch.pickle\")\n",
    "\n",
    "\n",
    "organize_data(\"/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Dataset/new_human\",\n",
    "              \"/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Dataset/new_ai\",\n",
    "              \"/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/\")\n"
   ],
   "id": "fbff5cd9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      " 40%|████      | 8/20 [01:48<02:44, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped non-image file: .DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [04:06<00:27, 13.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped non-image file: .DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:34<00:00, 13.71s/it]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:50:36.639192Z",
     "start_time": "2024-11-08T03:22:16.077506Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "232f6045a5c8dcdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "fe97613e7378c577"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "191611fd384d9acb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:50:36.639305Z",
     "start_time": "2024-11-08T03:22:16.104385Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b3dc90ccfe2159f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
