{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f51f19c",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "The code organizes the dataset of images into training and test sets for three categories: human, dalle, and stable. Random samples are selected from each category for training and the remaining samples are used for testing. The images are preprocessed, resized, and converted into numpy arrays. Training and test batches are created and saved as pickle files for later use."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T05:04:00.502143Z",
     "start_time": "2024-11-11T04:51:53.122173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle as pkl\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import webp\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# lấy ngẫu nhiên file theo số lượng file trong list \n",
    "def get_random_samples(file_list, sample_size):\n",
    "    \"\"\"Randomly selects samples from the given file list.\"\"\"\n",
    "    return random.sample(file_list, sample_size)\n",
    "\n",
    "def get_remaining_samples(file_list, selected_samples):\n",
    "    \"\"\"Returns the samples not selected from the file list.\"\"\"\n",
    "    return [sample for sample in file_list if sample not in selected_samples]\n",
    "\n",
    "# load 1 ảnh từ đường dẫn lên, thay đổi kích thước của nó và chuẩn hoá giá trị pixel\n",
    "# /255 : Chuẩn hóa giá trị pixel về khoảng [0, 1], mảng ảnh là 1 mảng 3 chiều [233,145,66] -> [0.93;0,53;0.21]\n",
    "def preprocess_image(image_path, target_size):\n",
    "    \"\"\"Loads and preprocesses the image from the given path.\"\"\"\n",
    "    img = Image.open(image_path).resize(target_size)\n",
    "    return np.array(img.convert(\"RGB\")) / 255.\n",
    "\n",
    "def save_pickle_file(data, file_path):\n",
    "    \"\"\"Saves the data as a pickle file at the specified path.\"\"\"\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pkl.dump(data, f)\n",
    "\n",
    "def create_batches_with_labels(file_paths, folder, label):\n",
    "    data = []\n",
    "    labels = []\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.webp']\n",
    "    \n",
    "    for path in file_paths:\n",
    "        if os.path.splitext(path)[1].lower() in valid_extensions:\n",
    "            img = preprocess_image(os.path.join(folder, path), (256, 256))\n",
    "            data.append(img)\n",
    "            labels.append(label)  # Change label based on category\n",
    "        else:\n",
    "            print(f\"Skipped non-image file: {path}\")\n",
    "\n",
    "    return np.stack(data), np.array(labels)\n",
    "\n",
    "def organize_data(human_path, ai_path, folder):\n",
    "    # Image locations\n",
    "    print(\"Initializing paths...\")\n",
    "    human_path = human_path\n",
    "    ai_path = ai_path\n",
    "\n",
    "    # Create a new folder to save information\n",
    "    if not os.path.exists(folder + 'file_names/'):\n",
    "        os.makedirs(folder + 'file_names/')\n",
    "        print(f\"Created folder: {folder}file_names/\")\n",
    "    if not os.path.exists(folder + 'train_batches/'):\n",
    "        os.makedirs(folder + 'train_batches/')\n",
    "        print(f\"Created folder: {folder}train_batches/\")\n",
    "    if not os.path.exists(folder + 'test_batches/'):\n",
    "        os.makedirs(folder + 'test_batches/')\n",
    "        print(f\"Created folder: {folder}test_batches/\")\n",
    "\n",
    "    # Randomly select test and training samples for each category\n",
    "    human_files = os.listdir(human_path)\n",
    "    print(f\"Found {len(human_files)} human files.\")\n",
    "    human_train = get_random_samples(human_files, 840)\n",
    "    print(f\"Selected {len(human_train)} human train samples.\")\n",
    "    human_test = get_remaining_samples(human_files, human_train)\n",
    "    print(f\"Remaining human test samples: {len(human_test)}\")\n",
    "\n",
    "    ai_files = os.listdir(ai_path)\n",
    "    print(f\"Found {len(ai_files)} AI files.\")\n",
    "    ai_train = get_random_samples(ai_files, 840)\n",
    "    print(f\"Selected {len(ai_train)} AI train samples.\")\n",
    "    ai_test = get_remaining_samples(ai_files, ai_train)\n",
    "    print(f\"Remaining AI test samples: {len(ai_test)}\")\n",
    "\n",
    "    # Save the train and test sample names as pickle files\n",
    "    save_pickle_file([human_train, ai_train], folder + 'file_names/train.pickle')\n",
    "    print(\"Saved train sample names to train.pickle.\")\n",
    "    save_pickle_file([human_test, ai_test], folder + 'file_names/test.pickle')\n",
    "    print(\"Saved test sample names to test.pickle.\")\n",
    "\n",
    "    # Create training batches\n",
    "    num_batches = 14\n",
    "    batch_size = 60\n",
    "    print(f\"Creating {num_batches} batches with batch size of {batch_size}...\")\n",
    "    \n",
    "    human_label = [0, 1]\n",
    "    ai_label = [1, 0]\n",
    "    \n",
    "    # tqdm dùng để hiển thị ra thanh progress màu đỏ\n",
    "    \n",
    "    for batch in tqdm(range(num_batches)):\n",
    "        # truy cập đến dữ liệu trong khoảng batch*batch_size tới (batch+1)*batch_size\n",
    "        human_train_batch = human_train[batch * batch_size:(batch + 1) * batch_size]\n",
    "        ai_train_batch = ai_train[batch * batch_size:(batch + 1) * batch_size]\n",
    "\n",
    "        # Process and save batches\n",
    "        # print(f\"Processing batch {batch + 1}/{num_batches}...\")\n",
    "        human_data, human_labels = create_batches_with_labels(human_train_batch, human_path, human_label)\n",
    "        # print(f\"Processed human batch {batch + 1}: {human_data.shape} images.\")\n",
    "        \n",
    "        ai_data, ai_labels = create_batches_with_labels(ai_train_batch, ai_path, ai_label)\n",
    "        # print(f\"Processed AI batch {batch + 1}: {ai_data.shape} images.\")\n",
    "\n",
    "        # Stack and save batch data\n",
    "        data_batch = {'data': np.vstack((human_data, ai_data)), \n",
    "                      'labels': np.vstack((human_labels, ai_labels))}\n",
    "\n",
    "        # print(f'data batch {data_batch}')\n",
    "        if data_batch['data'].size > 0 and data_batch['labels'].size > 0:\n",
    "            save_pickle_file(data_batch, f\"{folder}train_batches/batch_{batch}.pickle\")\n",
    "            print(f\"Saved batch {batch} to {folder}train_batches/batch_{batch}.pickle\")\n",
    "        else:\n",
    "            print(f\"Warning: Batch {batch} is empty and will not be saved.\")\n",
    "\n",
    "    # Repeat the process for test data\n",
    "    human_test_data, human_test_labels = create_batches_with_labels(human_test, human_path, human_label)\n",
    "    ai_test_data, ai_test_labels = create_batches_with_labels(ai_test, ai_path, ai_label)\n",
    "\n",
    "    # Stack test data and save\n",
    "    test_data = np.vstack((human_test_data, ai_test_data))\n",
    "    test_labels = np.vstack((human_test_labels, ai_test_labels))\n",
    "    test_batch = {'data': test_data, 'labels': test_labels}\n",
    "    save_pickle_file(test_batch, f\"{folder}test_batches/test_batch.pickle\")\n",
    "\n",
    "\n",
    "organize_data(\"/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Dataset/human\",\n",
    "              \"/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Dataset/ai_generated\",\n",
    "              \"/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/\")\n"
   ],
   "id": "fbff5cd9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing paths...\n",
      "Found 10001 human files.\n",
      "Selected 840 human train samples.\n",
      "Remaining human test samples: 9161\n",
      "Found 10000 AI files.\n",
      "Selected 840 AI train samples.\n",
      "Remaining AI test samples: 9160\n",
      "Saved train sample names to train.pickle.\n",
      "Saved test sample names to test.pickle.\n",
      "Creating 14 batches with batch size of 60...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/14 [00:01<00:15,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 0 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [00:02<00:14,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 1 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_1.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [00:03<00:13,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 2 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_2.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 4/14 [00:04<00:12,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 3 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_3.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 5/14 [00:06<00:11,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 4 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_4.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 6/14 [00:07<00:09,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 5 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_5.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 7/14 [00:08<00:08,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 6 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_6.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 8/14 [00:09<00:07,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 7 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_7.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 9/14 [00:11<00:06,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 8 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_8.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 10/14 [00:12<00:04,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 9 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_9.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 11/14 [00:13<00:03,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 10 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_10.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 12/14 [00:14<00:02,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 11 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_11.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [00:15<00:01,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 12 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_12.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:16<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 13 to /Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/train_batches/batch_13.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped non-image file: .DS_Store\n",
      "Skipped non-image file: .DS_Store\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 128\u001B[0m\n\u001B[1;32m    124\u001B[0m     test_batch \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m: test_data, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m: test_labels}\n\u001B[1;32m    125\u001B[0m     save_pickle_file(test_batch, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfolder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mtest_batches/test_batch.pickle\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 128\u001B[0m \u001B[43morganize_data\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Dataset/human\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m              \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Dataset/ai_generated\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m              \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/sakai/VIET_Working/STUDY_WORK/Ky5/Python/Image_Classifier/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[1], line 125\u001B[0m, in \u001B[0;36morganize_data\u001B[0;34m(human_path, ai_path, folder)\u001B[0m\n\u001B[1;32m    123\u001B[0m test_labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack((human_test_labels, ai_test_labels))\n\u001B[1;32m    124\u001B[0m test_batch \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m: test_data, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m: test_labels}\n\u001B[0;32m--> 125\u001B[0m \u001B[43msave_pickle_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mfolder\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43mtest_batches/test_batch.pickle\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[1], line 28\u001B[0m, in \u001B[0;36msave_pickle_file\u001B[0;34m(data, file_path)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Saves the data as a pickle file at the specified path.\"\"\"\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(file_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 28\u001B[0m     \u001B[43mpkl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mOSError\u001B[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T05:04:01.037185Z",
     "start_time": "2024-11-08T03:22:16.077506Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "232f6045a5c8dcdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "fe97613e7378c577"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "191611fd384d9acb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T03:22:16.106216Z",
     "start_time": "2024-11-08T03:22:16.104385Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b3dc90ccfe2159f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
